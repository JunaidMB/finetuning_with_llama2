# Finetuning LLama2 Using HuggingFace Transformers

This repository contains 2 notebooks which performs fine tuning for the Meta LLama2 model using the Transformers library. Inspiration is taken from Matt Shumer's fine tuning notebook (referenced). Both notebooks require GPU access so it's best to run them using Colab.

Going forward, we want to integrate Llama2 in a RAG pipeline and use it to fine tune more complex tasks.

## References

1. [Pinecone llama2 Guide](https://www.pinecone.io/learn/llama-2/)
2. H. Touvron, L. Martin, K. Stone, et. al., Llama 2: Open Foundation and Fine-Tuned Chat Models (2023), Meta AI
3. [LLM Field Guide](https://github.com/pinecone-io/examples/tree/master/learn/generation/llm-field-guide)
4. [Matt Shumer original repo](https://github.com/mshumer/gpt-llm-trainer)
5. [Efficient Fine-tuning Llama2 on a single GPU](https://www.youtube.com/watch?v=g68qlo9Izf0)
6. [LLama2 RAG pipeline example](https://github.com/JunaidMB/dppd_product_qa_llama2)